{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup \n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from official.nlp import optimization\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions for Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_filenames(path):\n",
    "    files = [] \n",
    "    for filename in os.listdir(path):\n",
    "        if not filename.endswith('.xml'):\n",
    "            continue\n",
    "        filepath = os.path.join(path, filename)\n",
    "        files.append(filepath)\n",
    "    return files\n",
    "\n",
    "def extract_train_chunks():\n",
    "    dataframe_collection = {} \n",
    "    for ctr in range(1,11):\n",
    "        positive_file_path = \"/Users/rajithamuthukrishnan/Desktop/uOttawa/Project_CSI6900/dataset/erisk 2019/eRisk2019_T1/training data - t1/2018 train/positive_examples/chunk\"+str(ctr)\n",
    "        negative_file_path = \"/Users/rajithamuthukrishnan/Desktop/uOttawa/Project_CSI6900/dataset/erisk 2019/eRisk2019_T1/training data - t1/2018 train/negative_examples/chunk\"+str(ctr)\n",
    "        positive_files = extract_filenames(positive_file_path)\n",
    "        negative_files = extract_filenames(negative_file_path)\n",
    "        files = positive_files + negative_files\n",
    "        data_list = []\n",
    "        for file in files:\n",
    "            if 'positive' in file:\n",
    "                label = 1\n",
    "            elif 'negative' in file:\n",
    "                label = 0\n",
    "            fd = open(file,'r')\n",
    "            data = fd.read()\n",
    "            soup = BeautifulSoup(data,'xml')\n",
    "            subject_id = soup.find('ID')\n",
    "            writings = soup.find_all('WRITING')\n",
    "            title = ''\n",
    "            text = ''\n",
    "            for writing in writings:\n",
    "                title = title + writing.find('TITLE').get_text() + ' '\n",
    "                text = text + writing.find('TEXT').get_text() + ' '\n",
    "                row = [subject_id.get_text(), title, text, label]\n",
    "            data_list.append(row)\n",
    "        chunk_name = 'chunk'+str(ctr)\n",
    "        dataframe_collection[chunk_name] = pd.DataFrame(data_list, columns = ['subject_id', 'title', 'text', 'label'])\n",
    "    return dataframe_collection\n",
    "\n",
    "\n",
    "def extract_test_chunks():\n",
    "    dataframe_collection = {} \n",
    "    for ctr in range(1,11):\n",
    "        file_path = \"/Users/rajithamuthukrishnan/Desktop/uOttawa/Project_CSI6900/dataset/erisk 2019/eRisk2019_T1/training data - t1/2018 test/chunk\"+str(ctr)\n",
    "        files = extract_filenames(file_path)\n",
    "        data_list = []\n",
    "        for file in files:\n",
    "            fd = open(file,'r')\n",
    "            data = fd.read()\n",
    "            soup = BeautifulSoup(data,'xml')\n",
    "            subject_id = soup.find('ID')\n",
    "            writings = soup.find_all('WRITING')\n",
    "            title = ''\n",
    "            text = ''\n",
    "            for writing in writings:\n",
    "                title = title + writing.find('TITLE').get_text() + ' '\n",
    "                text = text + writing.find('TEXT').get_text() + ' '\n",
    "                row = [subject_id.get_text(), title, text]\n",
    "            data_list.append(row)\n",
    "        chunk_name = 'chunk'+str(ctr)\n",
    "        dataframe_collection[chunk_name] = pd.DataFrame(data_list, columns = ['subject_id', 'title', 'text'])\n",
    "    return dataframe_collection\n",
    "\n",
    "def stemSentence(sentence):\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    token_words=word_tokenize(sentence)\n",
    "    token_words\n",
    "    stem_sentence=[]\n",
    "    for word in token_words:\n",
    "        stem_sentence.append(lemmatizer.lemmatize(word))\n",
    "        stem_sentence.append(\" \")\n",
    "    return \"\".join(stem_sentence)\n",
    "\n",
    "# Preprocess, encode data (word embeddings) for every chunk\n",
    "def preprocess_data(df):\n",
    "#   TITLE CLEAN\n",
    "    df['title_clean'] = df['title'].loc[df['title'] ==  ' [removed] '] = ' '\n",
    "    df['title_clean'] = df['title'].str.lower()\n",
    "    df['title_clean'] = df['title_clean'].apply(lambda elem: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", elem))  \n",
    "    # remove numbers\n",
    "    df['title_clean'] = df['title_clean'].apply(lambda elem: re.sub(r\"\\d+\", \"\", elem))\n",
    "    # remove duplicate spaces\n",
    "    df['title_clean'] = df['title_clean'].apply(lambda elem: re.sub(' +', ' ', elem))\n",
    "    # remove stop words\n",
    "    df['title_clean'] = df['title_clean'].apply(lambda elem: remove_stopwords(elem))\n",
    "    df['title_clean'] = df['title_clean'].apply(lambda elem: stemSentence(elem))\n",
    "    \n",
    "#   TEXT CLEAN\n",
    "    df['text_clean'] = df['text'].loc[df['title'] ==  ' [removed] '] = ' '\n",
    "    df['text_clean'] = df['text'].str.lower()\n",
    "    df['text_clean'] = df['text_clean'].apply(lambda elem: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", elem))  \n",
    "    # remove numbers\n",
    "    df['text_clean'] = df['text_clean'].apply(lambda elem: re.sub(r\"\\d+\", \"\", elem))\n",
    "    # remove duplicate spaces\n",
    "    df['text_clean'] = df['text_clean'].apply(lambda elem: re.sub(' +', ' ', elem))\n",
    "    # remove stop words\n",
    "    df['text_clean'] = df['text_clean'].apply(lambda elem: remove_stopwords(elem))\n",
    "    df['text_clean'] = df['text_clean'].apply(lambda elem: stemSentence(elem))\n",
    "    \n",
    "    df['final_text'] = df['title_clean'] + df['text_clean']\n",
    "    \n",
    "    final_dataset = pd.DataFrame(df['subject_id'])\n",
    "    final_dataset['text'] = df['title_clean'] + ' ' + df['final_text']\n",
    "    if 'label' in df.columns:\n",
    "        final_dataset['label'] = df['label']\n",
    "    \n",
    "    return final_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Hashing Vectorizer\n",
    "def vectorize_data(text_input, vectorizer, vec_type):\n",
    "\n",
    "    if vec_type == 'Hash':\n",
    "        data_vectorized = vectorizer.transform(text_input)\n",
    "\n",
    "    elif vec_type == 'BERT':\n",
    "        data_vectorized = vectorizer.predict(text_input)\n",
    "        \n",
    "    return data_vectorized\n",
    "\n",
    "# Function for model training with Hashing Vectorizer\n",
    "def train(train_df_collection, model):\n",
    "    vectorizer = HashingVectorizer()\n",
    "    metrics_list = []\n",
    "        \n",
    "    # Use only first 9 chunks for training and 10th chunk for validation     \n",
    "    for chunk in range (len(train_df_collection) - 1):\n",
    "        chunk_name = 'chunk'+str(chunk+1)\n",
    "        print('Training ' + chunk_name + '...')\n",
    "        df = preprocess_data(train_df_collection[chunk_name])\n",
    "        \n",
    "        train_input = df['text']\n",
    "        train_label = df['label']\n",
    "        \n",
    "        vectorizer.partial_fit(train_input)\n",
    "        \n",
    "        X_train = vectorize_data(train_input, vectorizer, vec_type='Hash')\n",
    "        Y_train = train_label\n",
    "            \n",
    "        if 'SGDClassifier' in str(type(model)):\n",
    "            if chunk_name == 'chunk1':\n",
    "                model.fit(X_train, Y_train)\n",
    "            else:\n",
    "                model.partial_fit(X_train, Y_train)\n",
    "        if 'LogisticRegression' in str(type(model)):\n",
    "            model.fit(X_train, Y_train)\n",
    "\n",
    "        predictions = model.predict(X_train)\n",
    "            \n",
    "        score = f1_score(Y_train, predictions, average='weighted')\n",
    "        metrics_list.append(score)\n",
    "        \n",
    "        print ('F1 Score :',f1_score(Y_train, predictions, average=None))\n",
    "        \n",
    "    metrics_df = pd.DataFrame(metrics_list, columns=['F1_score'])\n",
    "    return vectorizer\n",
    "    \n",
    "\n",
    "# Function for Bert Model creation\n",
    "def build_bert_model():\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "    preprocessing_layer = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3', name='preprocessing')\n",
    "    encoder_inputs = preprocessing_layer(text_input)\n",
    "    encoder = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4', trainable=True)\n",
    "    outputs = encoder(encoder_inputs)\n",
    "    net = outputs['pooled_output']\n",
    "    net = tf.keras.layers.Dense(100, name='features')(net)\n",
    "    net = tf.keras.layers.Dense(75)(net)\n",
    "    net = tf.keras.layers.Dense(50)(net)\n",
    "    net = tf.keras.layers.Dense(25)(net)\n",
    "    net = tf.keras.layers.Dense(10)(net)\n",
    "    net = tf.keras.layers.Dense(1, activation='sigmoid', name='classifier')(net)\n",
    "    model = tf.keras.Model(text_input, net)\n",
    "    \n",
    "    loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    metrics = tf.metrics.BinaryAccuracy()\n",
    "\n",
    "    init_lr = 3e-5\n",
    "    optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
    "                                              num_train_steps=1000,\n",
    "                                              num_warmup_steps=100,\n",
    "                                              optimizer_type='adamw')\n",
    "    model.compile(optimizer=optimizer,\n",
    "                       loss=loss,\n",
    "                       metrics=metrics)\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_bert(train_df_collection, model):\n",
    "    metrics_list = []\n",
    "    bert_model = build_bert_model()\n",
    "    \n",
    "    # Use only first 9 chunks for training and 10th chunk for validation \n",
    "    for chunk in range (len(train_df_collection)-1):\n",
    "        chunk_name = 'chunk'+str(chunk+1)\n",
    "        print('Training ' + chunk_name + '...')\n",
    "        df = preprocess_data(train_df_collection[chunk_name])\n",
    "        train_input = df['text']\n",
    "        train_label = df['label']\n",
    "        \n",
    "        bert_model.fit(train_input, train_label, class_weight={0:0.5,1:3.8}, epochs=5, verbose=0)\n",
    "        \n",
    "        vectorizer = Model(bert_model.input, outputs=bert_model.get_layer('features').output)\n",
    "        \n",
    "        X_train = vectorize_data(train_input, vectorizer, vec_type='BERT')\n",
    "        Y_train = train_label     \n",
    "                \n",
    "        if 'SGDClassifier' in str(type(model)):\n",
    "            if chunk_name == 'chunk1':\n",
    "                model.fit(X_train, Y_train)\n",
    "            else:\n",
    "                model.partial_fit(X_train, Y_train)\n",
    "        if 'LogisticRegression' in str(type(model)):\n",
    "            model.fit(X_train, Y_train)\n",
    "\n",
    "        predictions = model.predict(X_train)\n",
    "            \n",
    "        score = f1_score(Y_train, predictions, average='weighted')\n",
    "        metrics_list.append(score)\n",
    "        \n",
    "        print ('F1 Score :',f1_score(Y_train, predictions, average=None))\n",
    "    metrics_df = pd.DataFrame(metrics_list, columns=['F1_score'])\n",
    "    \n",
    "    return vectorizer\n",
    "\n",
    "def validate(df, model, vectorizer, vec_type):\n",
    "    \n",
    "    df = preprocess_data(df)\n",
    "    val_input = df['text']\n",
    "    val_label = df['label']\n",
    "    \n",
    "    X_val = vectorize_data(val_input, vectorizer, vec_type=vec_type)\n",
    "    Y_val = val_label\n",
    "    \n",
    "    predictions = model.predict(X_val)\n",
    "\n",
    "    print()\n",
    "    print(classification_report(Y_val, predictions, target_names=['Non-Anorexic', 'Anorexic']))\n",
    "    \n",
    "    \n",
    "def test_model(test_chunk_collection, test_labels, model, vectorizer, vec_type):\n",
    "    \n",
    "    for chunk in range(1,11):\n",
    "        chunk_name = 'chunk'+str(chunk)\n",
    "        chunk_df = test_chunk_collection[chunk_name]\n",
    "\n",
    "        # preprocess, vectorize and predict\n",
    "        clean_df = preprocess_data(chunk_df)\n",
    "\n",
    "        X_test = vectorize_data(clean_df.text, vectorizer, vec_type=vec_type)\n",
    "\n",
    "        chunk_pred = model.predict(X_test)\n",
    "\n",
    "        # Save prediction\n",
    "        pred_df = pd.DataFrame(chunk_pred, columns=['pred'])\n",
    "        pred_df.pred = pred_df.pred.astype('int')\n",
    "\n",
    "        # save predictions to dataframe\n",
    "        chunks_pred_df = pd.DataFrame(clean_df['subject_id'])\n",
    "        chunks_pred_df['pred'] = pred_df['pred'].values\n",
    "\n",
    "    # Map chunk predictions with truth labels\n",
    "    test_pred_list = []\n",
    "    for sub in chunks_pred_df['subject_id']:\n",
    "        value = test_labels.loc[test_labels['subject_id']==sub]['label'].values[0]\n",
    "        value_list = [sub, value]\n",
    "        test_pred_list.append(value_list)\n",
    "    final_test_pred = pd.DataFrame(test_pred_list, columns=['subject_id', 'label'])    \n",
    "    \n",
    "    # Print classification report\n",
    "    print(classification_report(final_test_pred['label'], chunks_pred_df['pred']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Data - Chunks 1 - 9\n",
    "train_dataframe_collection = extract_train_chunks()\n",
    "\n",
    "# Validation Data - Chunk 10\n",
    "val_df = train_dataframe_collection['chunk10']\n",
    "\n",
    "# Test Data\n",
    "test_dataframe_collection = extract_test_chunks()\n",
    "test_truth_labels = pd.read_csv('/Users/rajithamuthukrishnan/Desktop/uOttawa/Project_CSI6900/dataset/erisk 2019/eRisk2019_T1/training data - t1/2018 test/risk-golden-truth-test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57575758 3.8       ]\n"
     ]
    }
   ],
   "source": [
    "class_weights = compute_class_weight('balanced', classes=np.array([0,1]), y=val_df['label'])\n",
    "print((class_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models - Hash Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training chunk1...\n",
      "F1 Score : [1. 1.]\n",
      "Training chunk2...\n",
      "F1 Score : [0.78899083 0.46511628]\n",
      "Training chunk3...\n",
      "F1 Score : [0.97297297 0.84444444]\n",
      "Training chunk4...\n",
      "F1 Score : [0.94820717 0.75471698]\n",
      "Training chunk5...\n",
      "F1 Score : [0.91358025 0.6557377 ]\n",
      "Training chunk6...\n",
      "F1 Score : [0.97276265 0.85106383]\n",
      "Training chunk7...\n",
      "F1 Score : [0.96470588 0.81632653]\n",
      "Training chunk8...\n",
      "F1 Score : [0.97276265 0.85106383]\n",
      "Training chunk9...\n",
      "F1 Score : [0.98069498 0.88888889]\n"
     ]
    }
   ],
   "source": [
    "sgd_clf = SGDClassifier(loss='log_loss', class_weight={0:0.57, 1:3.8}, warm_start=True, learning_rate='adaptive', eta0=2)\n",
    "sgd_vectorizer = train(train_dataframe_collection, sgd_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Anorexic       0.98      0.93      0.95       132\n",
      "    Anorexic       0.65      0.85      0.74        20\n",
      "\n",
      "    accuracy                           0.92       152\n",
      "   macro avg       0.82      0.89      0.85       152\n",
      "weighted avg       0.93      0.92      0.93       152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "validate(val_df, sgd_clf, sgd_vectorizer, vec_type='Hash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to \"test_predictions\" folder\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.88      0.92       279\n",
      "           1       0.50      0.80      0.62        41\n",
      "\n",
      "    accuracy                           0.87       320\n",
      "   macro avg       0.73      0.84      0.77       320\n",
      "weighted avg       0.91      0.87      0.88       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_model(test_dataframe_collection, test_truth_labels, sgd_clf, sgd_vectorizer, vec_type='Hash')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training chunk1...\n",
      "F1 Score : [0.99619772 0.97560976]\n",
      "Training chunk2...\n",
      "F1 Score : [0.98850575 0.93023256]\n",
      "Training chunk3...\n",
      "F1 Score : [0.99236641 0.95238095]\n",
      "Training chunk4...\n",
      "F1 Score : [1. 1.]\n",
      "Training chunk5...\n",
      "F1 Score : [0.99619772 0.97560976]\n",
      "Training chunk6...\n",
      "F1 Score : [0.99236641 0.95238095]\n",
      "Training chunk7...\n",
      "F1 Score : [1. 1.]\n",
      "Training chunk8...\n",
      "F1 Score : [0.99236641 0.95238095]\n",
      "Training chunk9...\n",
      "F1 Score : [1. 1.]\n"
     ]
    }
   ],
   "source": [
    "lr_clf = LogisticRegression(solver='lbfgs', class_weight='balanced', warm_start=True)\n",
    "lr_vectorizer = train(train_dataframe_collection, lr_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Anorexic       0.94      0.99      0.96       132\n",
      "    Anorexic       0.92      0.55      0.69        20\n",
      "\n",
      "    accuracy                           0.93       152\n",
      "   macro avg       0.93      0.77      0.83       152\n",
      "weighted avg       0.93      0.93      0.93       152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "validate(val_df, lr_clf, lr_vectorizer, vec_type='Hash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to \"test_predictions\" folder\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95       279\n",
      "           1       0.74      0.56      0.64        41\n",
      "\n",
      "    accuracy                           0.92       320\n",
      "   macro avg       0.84      0.77      0.80       320\n",
      "weighted avg       0.91      0.92      0.91       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_model(test_dataframe_collection, test_truth_labels, lr_clf, lr_vectorizer, vec_type='Hash')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training chunk1...\n",
      "F1 Score : [1. 1.]\n",
      "Training chunk2...\n",
      "F1 Score : [0.936     0.7037037]\n",
      "Training chunk3...\n",
      "F1 Score : [0.98084291 0.88372093]\n",
      "Training chunk4...\n",
      "F1 Score : [0.96923077 0.81818182]\n",
      "Training chunk5...\n",
      "F1 Score : [0.97276265 0.85106383]\n",
      "Training chunk6...\n",
      "F1 Score : [0.94820717 0.75471698]\n",
      "Training chunk7...\n",
      "F1 Score : [0.94820717 0.75471698]\n",
      "Training chunk8...\n",
      "F1 Score : [0.98069498 0.88888889]\n",
      "Training chunk9...\n",
      "F1 Score : [0.944      0.74074074]\n"
     ]
    }
   ],
   "source": [
    "svm_clf = SGDClassifier(loss='hinge', penalty='l2', class_weight={0:0.57, 1:3.8}, warm_start=True)\n",
    "svm_vectorizer = train(train_dataframe_collection,svm_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Anorexic       0.98      0.86      0.92       132\n",
      "    Anorexic       0.50      0.90      0.64        20\n",
      "\n",
      "    accuracy                           0.87       152\n",
      "   macro avg       0.74      0.88      0.78       152\n",
      "weighted avg       0.92      0.87      0.88       152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "validate(val_df, svm_clf, svm_vectorizer, vec_type='Hash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to \"test_predictions\" folder\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.82      0.89       279\n",
      "           1       0.40      0.83      0.54        41\n",
      "\n",
      "    accuracy                           0.82       320\n",
      "   macro avg       0.69      0.83      0.72       320\n",
      "weighted avg       0.90      0.82      0.85       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_model(test_dataframe_collection, test_truth_labels, svm_clf, svm_vectorizer, vec_type='Hash')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models - BERT as Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training chunk1...\n",
      "F1 Score : [0.93650794 0.69230769]\n",
      "Training chunk2...\n",
      "F1 Score : [0.98084291 0.88372093]\n",
      "Training chunk3...\n",
      "F1 Score : [1. 1.]\n",
      "Training chunk4...\n",
      "F1 Score : [0.98069498 0.88888889]\n",
      "Training chunk5...\n",
      "F1 Score : [0.98867925 0.92307692]\n",
      "Training chunk6...\n",
      "F1 Score : [0.99619772 0.97560976]\n",
      "Training chunk7...\n",
      "F1 Score : [0.98113208 0.87179487]\n",
      "Training chunk8...\n",
      "F1 Score : [0.99242424 0.95      ]\n",
      "Training chunk9...\n",
      "F1 Score : [0.98484848 0.9       ]\n"
     ]
    }
   ],
   "source": [
    "sgd_bert_clf = SGDClassifier(loss='log_loss', class_weight={0:0.57, 1:3.8}, warm_start=True, learning_rate='adaptive', eta0=2)\n",
    "sgd_bert_vectorizer = train_bert(train_dataframe_collection, sgd_bert_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Anorexic       0.97      0.89      0.92       132\n",
      "    Anorexic       0.52      0.80      0.63        20\n",
      "\n",
      "    accuracy                           0.88       152\n",
      "   macro avg       0.74      0.84      0.78       152\n",
      "weighted avg       0.91      0.88      0.89       152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "validate(val_df, sgd_bert_clf, sgd_bert_vectorizer, vec_type='BERT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to \"test_predictions\" folder\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.89      0.92       279\n",
      "           1       0.47      0.68      0.56        41\n",
      "\n",
      "    accuracy                           0.86       320\n",
      "   macro avg       0.71      0.79      0.74       320\n",
      "weighted avg       0.89      0.86      0.87       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_model(test_dataframe_collection, test_truth_labels, sgd_bert_clf, sgd_bert_vectorizer, vec_type='BERT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training chunk1...\n",
      "F1 Score : [0.94208494 0.66666667]\n",
      "Training chunk2...\n",
      "F1 Score : [0.96946565 0.80952381]\n",
      "Training chunk3...\n",
      "F1 Score : [0.99236641 0.95238095]\n",
      "Training chunk4...\n",
      "F1 Score : [1. 1.]\n",
      "Training chunk5...\n",
      "F1 Score : [0.98850575 0.93023256]\n",
      "Training chunk6...\n",
      "F1 Score : [1. 1.]\n",
      "Training chunk7...\n",
      "F1 Score : [0.99619772 0.97560976]\n",
      "Training chunk8...\n",
      "F1 Score : [1. 1.]\n",
      "Training chunk9...\n",
      "F1 Score : [0.99242424 0.95      ]\n"
     ]
    }
   ],
   "source": [
    "lr_bert_clf = LogisticRegression(solver='lbfgs', class_weight='balanced', warm_start=True)\n",
    "lr_bert_vectorizer = train_bert(train_dataframe_collection, lr_bert_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Anorexic       0.95      0.95      0.95       132\n",
      "    Anorexic       0.68      0.65      0.67        20\n",
      "\n",
      "    accuracy                           0.91       152\n",
      "   macro avg       0.82      0.80      0.81       152\n",
      "weighted avg       0.91      0.91      0.91       152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "validate(val_df, lr_bert_clf, lr_bert_vectorizer, vec_type='BERT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to \"test_predictions\" folder\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       279\n",
      "           1       0.65      0.68      0.67        41\n",
      "\n",
      "    accuracy                           0.91       320\n",
      "   macro avg       0.80      0.81      0.81       320\n",
      "weighted avg       0.91      0.91      0.91       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_model(test_dataframe_collection, test_truth_labels, lr_bert_clf, lr_bert_vectorizer, vec_type='BERT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training chunk1...\n",
      "F1 Score : [0.29677419 0.26845638]\n",
      "Training chunk2...\n",
      "F1 Score : [0.93650794 0.69230769]\n",
      "Training chunk3...\n",
      "F1 Score : [0.98069498 0.88888889]\n",
      "Training chunk4...\n",
      "F1 Score : [1. 1.]\n",
      "Training chunk5...\n",
      "F1 Score : [0.98867925 0.92307692]\n",
      "Training chunk6...\n",
      "F1 Score : [0.99619772 0.97560976]\n",
      "Training chunk7...\n",
      "F1 Score : [0.99619772 0.97560976]\n",
      "Training chunk8...\n",
      "F1 Score : [1. 1.]\n",
      "Training chunk9...\n",
      "F1 Score : [1. 1.]\n"
     ]
    }
   ],
   "source": [
    "svm_bert_clf = SGDClassifier(loss='hinge', penalty='l2', class_weight={0:0.57, 1:3.8}, warm_start=True)\n",
    "svm_bert_vectorizer = train_bert(train_dataframe_collection, svm_bert_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Anorexic       0.93      0.96      0.95       132\n",
      "    Anorexic       0.69      0.55      0.61        20\n",
      "\n",
      "    accuracy                           0.91       152\n",
      "   macro avg       0.81      0.76      0.78       152\n",
      "weighted avg       0.90      0.91      0.90       152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "validate(val_df, svm_bert_clf, svm_bert_vectorizer, vec_type='BERT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to \"test_predictions\" folder\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95       279\n",
      "           1       0.73      0.46      0.57        41\n",
      "\n",
      "    accuracy                           0.91       320\n",
      "   macro avg       0.83      0.72      0.76       320\n",
      "weighted avg       0.90      0.91      0.90       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_model(test_dataframe_collection, test_truth_labels, svm_bert_clf, svm_bert_vectorizer, vec_type='BERT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_dev",
   "language": "python",
   "name": "project_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
