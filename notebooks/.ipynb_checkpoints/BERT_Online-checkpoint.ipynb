{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rajithamuthukrishnan/opt/anaconda3/lib/python3.8/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/Users/rajithamuthukrishnan/opt/anaconda3/lib/python3.8/site-packages/tensorflow_addons/utils/ensure_tf_install.py:54: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.2.0 and strictly below 2.4.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.8.4 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup \n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from official.nlp import optimization\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions for Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_filenames(path):\n",
    "    files = [] \n",
    "    for filename in os.listdir(path):\n",
    "        if not filename.endswith('.xml'):\n",
    "            continue\n",
    "        filepath = os.path.join(path, filename)\n",
    "        files.append(filepath)\n",
    "    return files\n",
    "\n",
    "def extract_train_chunks():\n",
    "    dataframe_collection = {} \n",
    "    for ctr in range(1,11):\n",
    "        positive_file_path = \"../dataset/2018 train/positive_examples/chunk\"+str(ctr)\n",
    "        negative_file_path = \"../dataset/2018 train/negative_examples/chunk\"+str(ctr)\n",
    "        positive_files = extract_filenames(positive_file_path)\n",
    "        negative_files = extract_filenames(negative_file_path)\n",
    "        files = positive_files + negative_files\n",
    "        data_list = []\n",
    "        for file in files:\n",
    "            if 'positive' in file:\n",
    "                label = 1\n",
    "            elif 'negative' in file:\n",
    "                label = 0\n",
    "            fd = open(file,'r')\n",
    "            data = fd.read()\n",
    "            soup = BeautifulSoup(data,'xml')\n",
    "            subject_id = soup.find('ID')\n",
    "            writings = soup.find_all('WRITING')\n",
    "            title = ''\n",
    "            text = ''\n",
    "            for writing in writings:\n",
    "                title = title + writing.find('TITLE').get_text() + ' '\n",
    "                text = text + writing.find('TEXT').get_text() + ' '\n",
    "                row = [subject_id.get_text(), title, text, label]\n",
    "            data_list.append(row)\n",
    "        chunk_name = 'chunk'+str(ctr)\n",
    "        dataframe_collection[chunk_name] = pd.DataFrame(data_list, columns = ['subject_id', 'title', 'text', 'label'])\n",
    "    return dataframe_collection\n",
    "\n",
    "\n",
    "def extract_test_chunks():\n",
    "    dataframe_collection = {} \n",
    "    for ctr in range(1,11):\n",
    "        file_path = \"../dataset/2018 test/chunk\"+str(ctr)\n",
    "        files = extract_filenames(file_path)\n",
    "        data_list = []\n",
    "        for file in files:\n",
    "            fd = open(file,'r')\n",
    "            data = fd.read()\n",
    "            soup = BeautifulSoup(data,'xml')\n",
    "            subject_id = soup.find('ID')\n",
    "            writings = soup.find_all('WRITING')\n",
    "            title = ''\n",
    "            text = ''\n",
    "            for writing in writings:\n",
    "                title = title + writing.find('TITLE').get_text() + ' '\n",
    "                text = text + writing.find('TEXT').get_text() + ' '\n",
    "                row = [subject_id.get_text(), title, text]\n",
    "            data_list.append(row)\n",
    "        chunk_name = 'chunk'+str(ctr)\n",
    "        dataframe_collection[chunk_name] = pd.DataFrame(data_list, columns = ['subject_id', 'title', 'text'])\n",
    "    return dataframe_collection\n",
    "\n",
    "def stemSentence(sentence):\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    token_words=word_tokenize(sentence)\n",
    "    token_words\n",
    "    stem_sentence=[]\n",
    "    for word in token_words:\n",
    "        stem_sentence.append(lemmatizer.lemmatize(word))\n",
    "        stem_sentence.append(\" \")\n",
    "    return \"\".join(stem_sentence)\n",
    "\n",
    "# Preprocess, encode data (word embeddings) for every chunk\n",
    "def preprocess_data(df):\n",
    "#   TITLE CLEAN\n",
    "    df['title_clean'] = df['title'].loc[df['title'] ==  ' [removed] '] = ' '\n",
    "    df['title_clean'] = df['title'].str.lower()\n",
    "    df['title_clean'] = df['title_clean'].apply(lambda elem: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", elem))  \n",
    "    # remove numbers\n",
    "    df['title_clean'] = df['title_clean'].apply(lambda elem: re.sub(r\"\\d+\", \"\", elem))\n",
    "    # remove duplicate spaces\n",
    "    df['title_clean'] = df['title_clean'].apply(lambda elem: re.sub(' +', ' ', elem))\n",
    "    # remove stop words\n",
    "    df['title_clean'] = df['title_clean'].apply(lambda elem: remove_stopwords(elem))\n",
    "    df['title_clean'] = df['title_clean'].apply(lambda elem: stemSentence(elem))\n",
    "    \n",
    "#   TEXT CLEAN\n",
    "    df['text_clean'] = df['text'].loc[df['title'] ==  ' [removed] '] = ' '\n",
    "    df['text_clean'] = df['text'].str.lower()\n",
    "    df['text_clean'] = df['text_clean'].apply(lambda elem: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", elem))  \n",
    "    # remove numbers\n",
    "    df['text_clean'] = df['text_clean'].apply(lambda elem: re.sub(r\"\\d+\", \"\", elem))\n",
    "    # remove duplicate spaces\n",
    "    df['text_clean'] = df['text_clean'].apply(lambda elem: re.sub(' +', ' ', elem))\n",
    "    # remove stop words\n",
    "    df['text_clean'] = df['text_clean'].apply(lambda elem: remove_stopwords(elem))\n",
    "    df['text_clean'] = df['text_clean'].apply(lambda elem: stemSentence(elem))\n",
    "    \n",
    "    df['final_text'] = df['title_clean'] + df['text_clean']\n",
    "    \n",
    "    final_dataset = pd.DataFrame(df['subject_id'])\n",
    "    final_dataset['text'] = df['title_clean'] + ' ' + df['final_text']\n",
    "    if 'label' in df.columns:\n",
    "        final_dataset['label'] = df['label']\n",
    "    \n",
    "    return final_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Bert Model creation\n",
    "def build_bert_model():\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "    preprocessing_layer = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3', name='preprocessing')\n",
    "    encoder_inputs = preprocessing_layer(text_input)\n",
    "    encoder = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4', trainable=True)\n",
    "    outputs = encoder(encoder_inputs)\n",
    "    net = outputs['pooled_output']\n",
    "    net = tf.keras.layers.Dense(100, name='features')(net)\n",
    "    net = tf.keras.layers.Dense(50)(net)\n",
    "    net = tf.keras.layers.Dense(10)(net)\n",
    "    net = tf.keras.layers.Dense(1, activation='sigmoid', name='classifier')(net)\n",
    "    model = tf.keras.Model(text_input, net)\n",
    "    \n",
    "    loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    metrics = tf.metrics.BinaryAccuracy()\n",
    "    model.compile(optimizer='Adagrad',\n",
    "                       loss=loss,\n",
    "                       metrics=metrics)\n",
    "\n",
    "    return model\n",
    "\n",
    "def train(train_df_collection, model):\n",
    "    metrics_list = []\n",
    "    \n",
    "    # Use only first 9 chunks for training and 10th chunk for validation \n",
    "    for chunk in range (len(train_df_collection)-1):\n",
    "#     for chunk in range (2):\n",
    "        chunk_name = 'chunk'+str(chunk+1)\n",
    "        print('Training ' + chunk_name + '...')\n",
    "        df = preprocess_data(train_df_collection[chunk_name])\n",
    "        X_train = df['text']\n",
    "        Y_train = df['label']\n",
    "        \n",
    "        model.fit(X_train, Y_train, class_weight={0:0.5,1:3.8}, epochs=5)\n",
    "#         model.fit(X_train, Y_train, epochs=1)\n",
    "        \n",
    "        predictions_probs = model.predict(X_train)\n",
    "        predictions = np.where(predictions_probs > 0.5, 1, 0)\n",
    "     \n",
    "        score = f1_score(Y_train, predictions, average='weighted')\n",
    "        metrics_list.append(score)\n",
    "        \n",
    "        print ('F1 Score :',f1_score(Y_train, predictions, average=None))\n",
    "    metrics_df = pd.DataFrame(metrics_list, columns=['F1_score'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def validate(df, model):\n",
    "    \n",
    "    df = preprocess_data(df)\n",
    "    X_val = df['text']\n",
    "    Y_val = df['label']\n",
    "    \n",
    "    predictions_probs = model.predict(X_val)\n",
    "    predictions = np.where(predictions_probs > 0.5, 1, 0)\n",
    "\n",
    "    print()\n",
    "    print(classification_report(Y_val, predictions, target_names=['Non-Anorexic', 'Anorexic']))\n",
    "    \n",
    "    \n",
    "def test_model(test_chunk_collection, test_labels, model):\n",
    "    \n",
    "    for chunk in range(1,11):\n",
    "        chunk_name = 'chunk'+str(chunk)\n",
    "        chunk_df = test_chunk_collection[chunk_name]\n",
    "\n",
    "        # preprocess, vectorize and predict\n",
    "        clean_df = preprocess_data(chunk_df)\n",
    "\n",
    "        X_test = clean_df.text\n",
    "        \n",
    "        chunk_probs = model.predict(X_test)\n",
    "        chunk_pred = np.where(chunk_probs > 0.5, 1, 0)\n",
    "\n",
    "\n",
    "        # Save prediction\n",
    "        pred_df = pd.DataFrame(chunk_pred, columns=['pred'])\n",
    "        pred_df.pred = pred_df.pred.astype('int')\n",
    "\n",
    "        # save predictions to dataframe\n",
    "        chunks_pred_df = pd.DataFrame(clean_df['subject_id'])\n",
    "        chunks_pred_df['pred'] = pred_df['pred'].values\n",
    "\n",
    "    # Map chunk predictions with truth labels\n",
    "    test_pred_list = []\n",
    "    for sub in chunks_pred_df['subject_id']:\n",
    "        value = test_labels.loc[test_labels['subject_id']==sub]['label'].values[0]\n",
    "        value_list = [sub, value]\n",
    "        test_pred_list.append(value_list)\n",
    "    final_test_pred = pd.DataFrame(test_pred_list, columns=['subject_id', 'label'])    \n",
    "    \n",
    "    # Print classification report\n",
    "    print(classification_report(final_test_pred['label'], chunks_pred_df['pred']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Data - Chunks 1 - 9\n",
    "train_dataframe_collection = extract_train_chunks()\n",
    "\n",
    "# Validation Data - Chunk 10\n",
    "val_df = train_dataframe_collection['chunk10']\n",
    "\n",
    "# Test Data\n",
    "test_dataframe_collection = extract_test_chunks()\n",
    "test_truth_labels = pd.read_csv('../dataset/2018 test/risk-golden-truth-test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57575758 3.8       ]\n"
     ]
    }
   ],
   "source": [
    "class_weights = compute_class_weight('balanced', classes=np.array([0,1]), y=val_df['label'])\n",
    "print((class_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_clf = build_bert_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " text (InputLayer)              [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " preprocessing (KerasLayer)     {'input_mask': (Non  0           ['text[0][0]']                   \n",
      "                                e, 128),                                                          \n",
      "                                 'input_word_ids':                                                \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_type_ids':                                                \n",
      "                                (None, 128)}                                                      \n",
      "                                                                                                  \n",
      " keras_layer_6 (KerasLayer)     {'sequence_output':  109482241   ['preprocessing[0][0]',          \n",
      "                                 (None, 128, 768),                'preprocessing[0][1]',          \n",
      "                                 'encoder_outputs':               'preprocessing[0][2]']          \n",
      "                                 [(None, 128, 768),                                               \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768)],                                               \n",
      "                                 'default': (None,                                                \n",
      "                                768),                                                             \n",
      "                                 'pooled_output': (                                               \n",
      "                                None, 768)}                                                       \n",
      "                                                                                                  \n",
      " features (Dense)               (None, 100)          76900       ['keras_layer_6[0][13]']         \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 50)           5050        ['features[0][0]']               \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 10)           510         ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      " classifier (Dense)             (None, 1)            11          ['dense_13[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,564,712\n",
      "Trainable params: 109,564,711\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bert_clf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training chunk1...\n",
      "Epoch 1/5\n",
      "5/5 [==============================] - 76s 13s/step - loss: 1.0717 - binary_accuracy: 0.4474\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 58s 11s/step - loss: 0.6943 - binary_accuracy: 0.2434\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 57s 11s/step - loss: 0.6025 - binary_accuracy: 0.7171\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 70s 15s/step - loss: 0.6318 - binary_accuracy: 0.3487\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 62s 12s/step - loss: 0.6066 - binary_accuracy: 0.6776\n",
      "F1 Score : [0.         0.23255814]\n",
      "Training chunk2...\n",
      "Epoch 1/5\n",
      "5/5 [==============================] - 62s 12s/step - loss: 0.6010 - binary_accuracy: 0.5000\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 62s 12s/step - loss: 0.5620 - binary_accuracy: 0.7829\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 59s 12s/step - loss: 0.6381 - binary_accuracy: 0.5724\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 61s 12s/step - loss: 0.5506 - binary_accuracy: 0.6053\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 61s 12s/step - loss: 0.4057 - binary_accuracy: 0.7105\n",
      "F1 Score : [0.93023256 0.60869565]\n",
      "Training chunk3...\n",
      "Epoch 1/5\n",
      "5/5 [==============================] - 61s 12s/step - loss: 0.6975 - binary_accuracy: 0.6316\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 61s 12s/step - loss: 0.4943 - binary_accuracy: 0.7566\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 63s 12s/step - loss: 0.4479 - binary_accuracy: 0.7632\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 61s 12s/step - loss: 0.4465 - binary_accuracy: 0.7697\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 66s 13s/step - loss: 0.2740 - binary_accuracy: 0.8882\n",
      "F1 Score : [0.70588235 0.4       ]\n",
      "Training chunk4...\n",
      "Epoch 1/5\n",
      "5/5 [==============================] - 65s 13s/step - loss: 0.7257 - binary_accuracy: 0.5789\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 67s 13s/step - loss: 0.5675 - binary_accuracy: 0.6382\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 66s 13s/step - loss: 0.3681 - binary_accuracy: 0.8158\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 66s 13s/step - loss: 0.3234 - binary_accuracy: 0.8092\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 67s 14s/step - loss: 0.4486 - binary_accuracy: 0.7368\n",
      "F1 Score : [0.91358025 0.6557377 ]\n",
      "Training chunk5...\n",
      "Epoch 1/5\n",
      "5/5 [==============================] - 63s 13s/step - loss: 0.5657 - binary_accuracy: 0.7763\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 62s 11s/step - loss: 0.3999 - binary_accuracy: 0.8289\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 57s 11s/step - loss: 0.3417 - binary_accuracy: 0.8289\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 57s 11s/step - loss: 0.3156 - binary_accuracy: 0.8487\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 57s 11s/step - loss: 0.2747 - binary_accuracy: 0.8553\n",
      "F1 Score : [0.95275591 0.76      ]\n",
      "Training chunk6...\n",
      "Epoch 1/5\n",
      "5/5 [==============================] - 63s 13s/step - loss: 0.4661 - binary_accuracy: 0.8684\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 57s 11s/step - loss: 0.3882 - binary_accuracy: 0.8355\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 57s 11s/step - loss: 0.4170 - binary_accuracy: 0.7500\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 57s 11s/step - loss: 0.2959 - binary_accuracy: 0.8158\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 57s 11s/step - loss: 0.2290 - binary_accuracy: 0.9145\n",
      "F1 Score : [0.94071146 0.70588235]\n",
      "Training chunk7...\n",
      "Epoch 1/5\n",
      "5/5 [==============================] - 57s 11s/step - loss: 0.5213 - binary_accuracy: 0.7566\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 60s 12s/step - loss: 0.4378 - binary_accuracy: 0.8026\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 72s 14s/step - loss: 0.3546 - binary_accuracy: 0.8421\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 62s 12s/step - loss: 0.3387 - binary_accuracy: 0.8618\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 61s 12s/step - loss: 0.3484 - binary_accuracy: 0.8092\n",
      "F1 Score : [0.93172691 0.69090909]\n",
      "Training chunk8...\n",
      "Epoch 1/5\n",
      "5/5 [==============================] - 64s 13s/step - loss: 0.3706 - binary_accuracy: 0.8421\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 73s 15s/step - loss: 0.3084 - binary_accuracy: 0.8026\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 71s 14s/step - loss: 0.2181 - binary_accuracy: 0.8684\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 65s 13s/step - loss: 0.1746 - binary_accuracy: 0.9145\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 67s 12s/step - loss: 0.1442 - binary_accuracy: 0.9342\n",
      "F1 Score : [0.98069498 0.88888889]\n",
      "Training chunk9...\n",
      "Epoch 1/5\n",
      "5/5 [==============================] - 67s 12s/step - loss: 0.5231 - binary_accuracy: 0.8355\n",
      "Epoch 2/5\n",
      "5/5 [==============================] - 63s 12s/step - loss: 0.3122 - binary_accuracy: 0.8684\n",
      "Epoch 3/5\n",
      "5/5 [==============================] - 61s 12s/step - loss: 0.2790 - binary_accuracy: 0.8947\n",
      "Epoch 4/5\n",
      "5/5 [==============================] - 60s 12s/step - loss: 0.2262 - binary_accuracy: 0.8947\n",
      "Epoch 5/5\n",
      "5/5 [==============================] - 60s 12s/step - loss: 0.1782 - binary_accuracy: 0.9211\n",
      "F1 Score : [0.9609375  0.79166667]\n"
     ]
    }
   ],
   "source": [
    "bert_online = train(train_dataframe_collection, bert_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "Non-Anorexic       0.95      0.94      0.94       132\n",
      "    Anorexic       0.62      0.65      0.63        20\n",
      "\n",
      "    accuracy                           0.90       152\n",
      "   macro avg       0.78      0.79      0.79       152\n",
      "weighted avg       0.90      0.90      0.90       152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "validate(val_df, bert_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       279\n",
      "           1       0.67      0.63      0.65        41\n",
      "\n",
      "    accuracy                           0.91       320\n",
      "   macro avg       0.81      0.79      0.80       320\n",
      "weighted avg       0.91      0.91      0.91       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_model(test_dataframe_collection, test_truth_labels, bert_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_dev",
   "language": "python",
   "name": "project_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
